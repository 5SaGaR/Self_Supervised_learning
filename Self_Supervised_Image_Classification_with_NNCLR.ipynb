{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJB-00Be09fn",
        "outputId": "c97fe3a0-6c0d-4de7-a4c2-cb6e7b835c96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (4.9.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.23.5)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (4.66.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.14.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (6.1.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (4.9.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2024.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.62.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://paperswithcode.com/method/nnclr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8ydfg9wT1J-V"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YX1hVobn1M4t"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "shuffle_buffer = 5000\n",
        "# The below two values are taken from https://www.tensorflow.org/datasets/catalog/stl10\n",
        "labelled_train_images = 5000\n",
        "unlabelled_images = 100000\n",
        "\n",
        "temperature = 0.11\n",
        "queue_size = 9000\n",
        "contrastive_augmenter = {\n",
        "    \"brightness\": 0.5,\n",
        "    \"name\": \"contrastive_augmenter\",\n",
        "    \"scale\": (0.2, 1.0),\n",
        "}\n",
        "classification_augmenter = {\n",
        "    \"brightness\": 0.2,\n",
        "    \"name\": \"classification_augmenter\",\n",
        "    \"scale\": (0.5, 1.0),\n",
        "}\n",
        "input_shape = (96, 96, 3)\n",
        "width = 128\n",
        "num_epochs = 25\n",
        "steps_per_epoch = 180\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_hwv6Fqd1QTF"
      },
      "outputs": [],
      "source": [
        "dataset_name = \"stl10\"\n",
        "\n",
        "\n",
        "def prepare_dataset():\n",
        "    unlabeled_batch_size = unlabelled_images // steps_per_epoch\n",
        "    labeled_batch_size = labelled_train_images // steps_per_epoch\n",
        "    batch_size = unlabeled_batch_size + labeled_batch_size\n",
        "\n",
        "    unlabeled_train_dataset = (\n",
        "        tfds.load(\n",
        "            dataset_name, split=\"unlabelled\", as_supervised=True, shuffle_files=True\n",
        "        )\n",
        "        .shuffle(buffer_size=shuffle_buffer)\n",
        "        .batch(unlabeled_batch_size, drop_remainder=True)\n",
        "    )\n",
        "    labeled_train_dataset = (\n",
        "        tfds.load(dataset_name, split=\"train\", as_supervised=True, shuffle_files=True)\n",
        "        .shuffle(buffer_size=shuffle_buffer)\n",
        "        .batch(labeled_batch_size, drop_remainder=True)\n",
        "    )\n",
        "    test_dataset = (\n",
        "        tfds.load(dataset_name, split=\"test\", as_supervised=True)\n",
        "        .batch(batch_size)\n",
        "        .prefetch(buffer_size=AUTOTUNE)\n",
        "    )\n",
        "    train_dataset = tf.data.Dataset.zip(\n",
        "        (unlabeled_train_dataset, labeled_train_dataset)\n",
        "    ).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    return batch_size, train_dataset, labeled_train_dataset, test_dataset\n",
        "\n",
        "\n",
        "batch_size, train_dataset, labeled_train_dataset, test_dataset = prepare_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "NbthGnle1di_"
      },
      "outputs": [],
      "source": [
        "class RandomResizedCrop(layers.Layer):\n",
        "    def __init__(self, scale, ratio):\n",
        "        super().__init__()\n",
        "        self.scale = scale\n",
        "        self.log_ratio = (tf.math.log(ratio[0]), tf.math.log(ratio[1]))\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        height = tf.shape(images)[1]\n",
        "        width = tf.shape(images)[2]\n",
        "\n",
        "        random_scales = tf.random.uniform((batch_size,), self.scale[0], self.scale[1])\n",
        "        random_ratios = tf.exp(\n",
        "            tf.random.uniform((batch_size,), self.log_ratio[0], self.log_ratio[1])\n",
        "        )\n",
        "\n",
        "        new_heights = tf.clip_by_value(tf.sqrt(random_scales / random_ratios), 0, 1)\n",
        "        new_widths = tf.clip_by_value(tf.sqrt(random_scales * random_ratios), 0, 1)\n",
        "        height_offsets = tf.random.uniform((batch_size,), 0, 1 - new_heights)\n",
        "        width_offsets = tf.random.uniform((batch_size,), 0, 1 - new_widths)\n",
        "\n",
        "        bounding_boxes = tf.stack(\n",
        "            [\n",
        "                height_offsets,\n",
        "                width_offsets,\n",
        "                height_offsets + new_heights,\n",
        "                width_offsets + new_widths,\n",
        "            ],\n",
        "            axis=1,\n",
        "        )\n",
        "        images = tf.image.crop_and_resize(\n",
        "            images, bounding_boxes, tf.range(batch_size), (height, width)\n",
        "        )\n",
        "        return images\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sT_par5J2cad"
      },
      "outputs": [],
      "source": [
        "class RandomBrightness(layers.Layer):\n",
        "    def __init__(self, brightness):\n",
        "        super().__init__()\n",
        "        self.brightness = brightness\n",
        "\n",
        "    def blend(self, images_1, images_2, ratios):\n",
        "        return tf.clip_by_value(ratios * images_1 + (1.0 - ratios) * images_2, 0, 1)\n",
        "\n",
        "    def random_brightness(self, images):\n",
        "        # random interpolation/extrapolation between the image and darkness\n",
        "        return self.blend(\n",
        "            images,\n",
        "            0,\n",
        "            tf.random.uniform(\n",
        "                (tf.shape(images)[0], 1, 1, 1), 1 - self.brightness, 1 + self.brightness\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    def call(self, images):\n",
        "        images = self.random_brightness(images)\n",
        "        return images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ovgPAKuY2e2Q"
      },
      "outputs": [],
      "source": [
        "def augmenter(brightness, name, scale):\n",
        "    return keras.Sequential(\n",
        "        [\n",
        "            layers.Input(shape=input_shape),\n",
        "            layers.Rescaling(1 / 255),\n",
        "            layers.RandomFlip(\"horizontal\"),\n",
        "            RandomResizedCrop(scale=scale, ratio=(3 / 4, 4 / 3)),\n",
        "            RandomBrightness(brightness=brightness),\n",
        "        ],\n",
        "        name=name,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "e471H6qh2hyL"
      },
      "outputs": [],
      "source": [
        "def encoder():\n",
        "    return keras.Sequential(\n",
        "        [\n",
        "            layers.Input(shape=input_shape),\n",
        "            layers.Conv2D(width, kernel_size=3, strides=2, activation=\"relu\"),\n",
        "            layers.Conv2D(width, kernel_size=3, strides=2, activation=\"relu\"),\n",
        "            layers.Conv2D(width, kernel_size=3, strides=2, activation=\"relu\"),\n",
        "            layers.Conv2D(width, kernel_size=3, strides=1, activation=\"relu\"),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(width, activation=\"relu\"),\n",
        "        ],\n",
        "        name=\"encoder\",\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "YSRH3vW12rP_"
      },
      "outputs": [],
      "source": [
        "class NNCLR(keras.Model):\n",
        "    def __init__(\n",
        "        self, temperature, queue_size,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.probe_accuracy = keras.metrics.SparseCategoricalAccuracy()\n",
        "        self.correlation_accuracy = keras.metrics.SparseCategoricalAccuracy()\n",
        "        self.contrastive_accuracy = keras.metrics.SparseCategoricalAccuracy()\n",
        "        self.probe_loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "        self.contrastive_augmenter = augmenter(**contrastive_augmenter)\n",
        "        self.classification_augmenter = augmenter(**classification_augmenter)\n",
        "        self.encoder = encoder()\n",
        "        self.projection_head = keras.Sequential(\n",
        "            [\n",
        "                layers.Input(shape=(width,)),\n",
        "                layers.Dense(width, activation=\"relu\"),\n",
        "                layers.Dense(width),\n",
        "            ],\n",
        "            name=\"projection_head\",\n",
        "        )\n",
        "        self.linear_probe = keras.Sequential(\n",
        "            [layers.Input(shape=(width,)), layers.Dense(10)], name=\"linear_probe\"\n",
        "        )\n",
        "        self.temperature = temperature\n",
        "\n",
        "        feature_dimensions = self.encoder.output_shape[1]\n",
        "        self.feature_queue = tf.Variable(\n",
        "            tf.math.l2_normalize(\n",
        "                tf.random.normal(shape=(queue_size, feature_dimensions)), axis=1\n",
        "            ),\n",
        "            trainable=False,\n",
        "        )\n",
        "\n",
        "    def compile(self, contrastive_optimizer, probe_optimizer, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "        self.contrastive_optimizer = contrastive_optimizer\n",
        "        self.probe_optimizer = probe_optimizer\n",
        "\n",
        "    def nearest_neighbour(self, projections):\n",
        "        support_similarities = tf.matmul(\n",
        "            projections, self.feature_queue, transpose_b=True\n",
        "        )\n",
        "        nn_projections = tf.gather(\n",
        "            self.feature_queue, tf.argmax(support_similarities, axis=1), axis=0\n",
        "        )\n",
        "        return projections + tf.stop_gradient(nn_projections - projections)\n",
        "\n",
        "    def update_contrastive_accuracy(self, features_1, features_2):\n",
        "        features_1 = tf.math.l2_normalize(features_1, axis=1)\n",
        "        features_2 = tf.math.l2_normalize(features_2, axis=1)\n",
        "        similarities = tf.matmul(features_1, features_2, transpose_b=True)\n",
        "\n",
        "        batch_size = tf.shape(features_1)[0]\n",
        "        contrastive_labels = tf.range(batch_size)\n",
        "        self.contrastive_accuracy.update_state(\n",
        "            tf.concat([contrastive_labels, contrastive_labels], axis=0),\n",
        "            tf.concat([similarities, tf.transpose(similarities)], axis=0),\n",
        "        )\n",
        "\n",
        "    def update_correlation_accuracy(self, features_1, features_2):\n",
        "        features_1 = (\n",
        "            features_1 - tf.reduce_mean(features_1, axis=0)\n",
        "        ) / tf.math.reduce_std(features_1, axis=0)\n",
        "        features_2 = (\n",
        "            features_2 - tf.reduce_mean(features_2, axis=0)\n",
        "        ) / tf.math.reduce_std(features_2, axis=0)\n",
        "\n",
        "        batch_size = tf.shape(features_1, out_type=tf.float32)[0]\n",
        "        cross_correlation = (\n",
        "            tf.matmul(features_1, features_2, transpose_a=True) / batch_size\n",
        "        )\n",
        "\n",
        "        feature_dim = tf.shape(features_1)[1]\n",
        "        correlation_labels = tf.range(feature_dim)\n",
        "        self.correlation_accuracy.update_state(\n",
        "            tf.concat([correlation_labels, correlation_labels], axis=0),\n",
        "            tf.concat([cross_correlation, tf.transpose(cross_correlation)], axis=0),\n",
        "        )\n",
        "\n",
        "    def contrastive_loss(self, projections_1, projections_2):\n",
        "        projections_1 = tf.math.l2_normalize(projections_1, axis=1)\n",
        "        projections_2 = tf.math.l2_normalize(projections_2, axis=1)\n",
        "\n",
        "        similarities_1_2_1 = (\n",
        "            tf.matmul(\n",
        "                self.nearest_neighbour(projections_1), projections_2, transpose_b=True\n",
        "            )\n",
        "            / self.temperature\n",
        "        )\n",
        "        similarities_1_2_2 = (\n",
        "            tf.matmul(\n",
        "                projections_2, self.nearest_neighbour(projections_1), transpose_b=True\n",
        "            )\n",
        "            / self.temperature\n",
        "        )\n",
        "\n",
        "        similarities_2_1_1 = (\n",
        "            tf.matmul(\n",
        "                self.nearest_neighbour(projections_2), projections_1, transpose_b=True\n",
        "            )\n",
        "            / self.temperature\n",
        "        )\n",
        "        similarities_2_1_2 = (\n",
        "            tf.matmul(\n",
        "                projections_1, self.nearest_neighbour(projections_2), transpose_b=True\n",
        "            )\n",
        "            / self.temperature\n",
        "        )\n",
        "\n",
        "        batch_size = tf.shape(projections_1)[0]\n",
        "        contrastive_labels = tf.range(batch_size)\n",
        "        loss = keras.losses.sparse_categorical_crossentropy(\n",
        "            tf.concat(\n",
        "                [\n",
        "                    contrastive_labels,\n",
        "                    contrastive_labels,\n",
        "                    contrastive_labels,\n",
        "                    contrastive_labels,\n",
        "                ],\n",
        "                axis=0,\n",
        "            ),\n",
        "            tf.concat(\n",
        "                [\n",
        "                    similarities_1_2_1,\n",
        "                    similarities_1_2_2,\n",
        "                    similarities_2_1_1,\n",
        "                    similarities_2_1_2,\n",
        "                ],\n",
        "                axis=0,\n",
        "            ),\n",
        "            from_logits=True,\n",
        "        )\n",
        "\n",
        "        self.feature_queue.assign(\n",
        "            tf.concat([projections_1, self.feature_queue[:-batch_size]], axis=0)\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "    def train_step(self, data):\n",
        "        (unlabeled_images, _), (labeled_images, labels) = data\n",
        "        images = tf.concat((unlabeled_images, labeled_images), axis=0)\n",
        "        augmented_images_1 = self.contrastive_augmenter(images)\n",
        "        augmented_images_2 = self.contrastive_augmenter(images)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            features_1 = self.encoder(augmented_images_1)\n",
        "            features_2 = self.encoder(augmented_images_2)\n",
        "            projections_1 = self.projection_head(features_1)\n",
        "            projections_2 = self.projection_head(features_2)\n",
        "            contrastive_loss = self.contrastive_loss(projections_1, projections_2)\n",
        "        gradients = tape.gradient(\n",
        "            contrastive_loss,\n",
        "            self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
        "        )\n",
        "        self.contrastive_optimizer.apply_gradients(\n",
        "            zip(\n",
        "                gradients,\n",
        "                self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
        "            )\n",
        "        )\n",
        "        self.update_contrastive_accuracy(features_1, features_2)\n",
        "        self.update_correlation_accuracy(features_1, features_2)\n",
        "        preprocessed_images = self.classification_augmenter(labeled_images)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            features = self.encoder(preprocessed_images)\n",
        "            class_logits = self.linear_probe(features)\n",
        "            probe_loss = self.probe_loss(labels, class_logits)\n",
        "        gradients = tape.gradient(probe_loss, self.linear_probe.trainable_weights)\n",
        "        self.probe_optimizer.apply_gradients(\n",
        "            zip(gradients, self.linear_probe.trainable_weights)\n",
        "        )\n",
        "        self.probe_accuracy.update_state(labels, class_logits)\n",
        "\n",
        "        return {\n",
        "            \"c_loss\": contrastive_loss,\n",
        "            \"c_acc\": self.contrastive_accuracy.result(),\n",
        "            \"r_acc\": self.correlation_accuracy.result(),\n",
        "            \"p_loss\": probe_loss,\n",
        "            \"p_acc\": self.probe_accuracy.result(),\n",
        "        }\n",
        "\n",
        "    def test_step(self, data):\n",
        "        labeled_images, labels = data\n",
        "\n",
        "        preprocessed_images = self.classification_augmenter(\n",
        "            labeled_images, training=False\n",
        "        )\n",
        "        features = self.encoder(preprocessed_images, training=False)\n",
        "        class_logits = self.linear_probe(features, training=False)\n",
        "        probe_loss = self.probe_loss(labels, class_logits)\n",
        "\n",
        "        self.probe_accuracy.update_state(labels, class_logits)\n",
        "        return {\"p_loss\": probe_loss, \"p_acc\": self.probe_accuracy.result()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr12gY4v2uuD",
        "outputId": "ebe279b5-880f-4596-a222-d48d67309e9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "180/180 [==============================] - 89s 452ms/step - c_loss: 3.4122 - c_acc: 0.3898 - r_acc: 0.4460 - p_loss: 2.2521 - p_acc: 0.1156 - val_p_loss: 2.1326 - val_p_acc: 0.2114\n",
            "Epoch 2/25\n",
            "180/180 [==============================] - 79s 416ms/step - c_loss: 2.2926 - c_acc: 0.6994 - r_acc: 0.5043 - p_loss: 2.0412 - p_acc: 0.2421 - val_p_loss: 1.9926 - val_p_acc: 0.2901\n",
            "Epoch 3/25\n",
            "180/180 [==============================] - 79s 414ms/step - c_loss: 2.0019 - c_acc: 0.7808 - r_acc: 0.4977 - p_loss: 1.9264 - p_acc: 0.3054 - val_p_loss: 1.9001 - val_p_acc: 0.3262\n",
            "Epoch 4/25\n",
            "180/180 [==============================] - 79s 417ms/step - c_loss: 1.8825 - c_acc: 0.8133 - r_acc: 0.4938 - p_loss: 1.8417 - p_acc: 0.3433 - val_p_loss: 1.7975 - val_p_acc: 0.3386\n",
            "Epoch 5/25\n",
            "180/180 [==============================] - 79s 413ms/step - c_loss: 1.7852 - c_acc: 0.8407 - r_acc: 0.4954 - p_loss: 1.7860 - p_acc: 0.3579 - val_p_loss: 1.7870 - val_p_acc: 0.3380\n",
            "Epoch 6/25\n",
            "180/180 [==============================] - 79s 420ms/step - c_loss: 1.7426 - c_acc: 0.8520 - r_acc: 0.4978 - p_loss: 1.7482 - p_acc: 0.3572 - val_p_loss: 1.7245 - val_p_acc: 0.3661\n",
            "Epoch 7/25\n",
            "180/180 [==============================] - 79s 415ms/step - c_loss: 1.7104 - c_acc: 0.8635 - r_acc: 0.4987 - p_loss: 1.7195 - p_acc: 0.3699 - val_p_loss: 1.6861 - val_p_acc: 0.3754\n",
            "Epoch 8/25\n",
            "180/180 [==============================] - 80s 418ms/step - c_loss: 1.6759 - c_acc: 0.8721 - r_acc: 0.4937 - p_loss: 1.6939 - p_acc: 0.3806 - val_p_loss: 1.7014 - val_p_acc: 0.3664\n",
            "Epoch 9/25\n",
            "180/180 [==============================] - 78s 413ms/step - c_loss: 1.6596 - c_acc: 0.8776 - r_acc: 0.4986 - p_loss: 1.6750 - p_acc: 0.3851 - val_p_loss: 1.6917 - val_p_acc: 0.3774\n",
            "Epoch 10/25\n",
            "180/180 [==============================] - 79s 419ms/step - c_loss: 1.6380 - c_acc: 0.8845 - r_acc: 0.4992 - p_loss: 1.6663 - p_acc: 0.3812 - val_p_loss: 1.7125 - val_p_acc: 0.3780\n",
            "Epoch 11/25\n",
            "180/180 [==============================] - 79s 415ms/step - c_loss: 1.6167 - c_acc: 0.8881 - r_acc: 0.4989 - p_loss: 1.6353 - p_acc: 0.3923 - val_p_loss: 1.6643 - val_p_acc: 0.3792\n",
            "Epoch 12/25\n",
            "180/180 [==============================] - 79s 412ms/step - c_loss: 1.6130 - c_acc: 0.8898 - r_acc: 0.5033 - p_loss: 1.6249 - p_acc: 0.3920 - val_p_loss: 1.6697 - val_p_acc: 0.3860\n",
            "Epoch 13/25\n",
            "180/180 [==============================] - 78s 414ms/step - c_loss: 1.5973 - c_acc: 0.8928 - r_acc: 0.5016 - p_loss: 1.6053 - p_acc: 0.3947 - val_p_loss: 1.6500 - val_p_acc: 0.3950\n",
            "Epoch 14/25\n",
            "180/180 [==============================] - 78s 414ms/step - c_loss: 1.5933 - c_acc: 0.8958 - r_acc: 0.5029 - p_loss: 1.5978 - p_acc: 0.4130 - val_p_loss: 1.6255 - val_p_acc: 0.3915\n",
            "Epoch 15/25\n",
            "180/180 [==============================] - 79s 412ms/step - c_loss: 1.5842 - c_acc: 0.9011 - r_acc: 0.5044 - p_loss: 1.5913 - p_acc: 0.4075 - val_p_loss: 1.6334 - val_p_acc: 0.3956\n",
            "Epoch 16/25\n",
            "180/180 [==============================] - 78s 413ms/step - c_loss: 1.5676 - c_acc: 0.9011 - r_acc: 0.5032 - p_loss: 1.5717 - p_acc: 0.4207 - val_p_loss: 1.6699 - val_p_acc: 0.3910\n",
            "Epoch 17/25\n",
            "180/180 [==============================] - 79s 411ms/step - c_loss: 1.5575 - c_acc: 0.9058 - r_acc: 0.5027 - p_loss: 1.5513 - p_acc: 0.4167 - val_p_loss: 1.6328 - val_p_acc: 0.3996\n",
            "Epoch 18/25\n",
            "180/180 [==============================] - 78s 412ms/step - c_loss: 1.5561 - c_acc: 0.9061 - r_acc: 0.5023 - p_loss: 1.5708 - p_acc: 0.4153 - val_p_loss: 1.6235 - val_p_acc: 0.4080\n",
            "Epoch 19/25\n",
            "180/180 [==============================] - 79s 412ms/step - c_loss: 1.5501 - c_acc: 0.9086 - r_acc: 0.5020 - p_loss: 1.5573 - p_acc: 0.4244 - val_p_loss: 1.6771 - val_p_acc: 0.3865\n",
            "Epoch 20/25\n",
            "180/180 [==============================] - 80s 424ms/step - c_loss: 1.5361 - c_acc: 0.9090 - r_acc: 0.5016 - p_loss: 1.5475 - p_acc: 0.4192 - val_p_loss: 1.6460 - val_p_acc: 0.3999\n",
            "Epoch 21/25\n",
            "180/180 [==============================] - 78s 413ms/step - c_loss: 1.5324 - c_acc: 0.9121 - r_acc: 0.5037 - p_loss: 1.5399 - p_acc: 0.4334 - val_p_loss: 1.6018 - val_p_acc: 0.4071\n",
            "Epoch 22/25\n",
            "180/180 [==============================] - 79s 414ms/step - c_loss: 1.5254 - c_acc: 0.9141 - r_acc: 0.5039 - p_loss: 1.5332 - p_acc: 0.4324 - val_p_loss: 1.5906 - val_p_acc: 0.4038\n",
            "Epoch 23/25\n",
            "180/180 [==============================] - 78s 412ms/step - c_loss: 1.5179 - c_acc: 0.9143 - r_acc: 0.5040 - p_loss: 1.5278 - p_acc: 0.4411 - val_p_loss: 1.6140 - val_p_acc: 0.4055\n",
            "Epoch 24/25\n",
            "180/180 [==============================] - 79s 412ms/step - c_loss: 1.5158 - c_acc: 0.9156 - r_acc: 0.5048 - p_loss: 1.5395 - p_acc: 0.4236 - val_p_loss: 1.6086 - val_p_acc: 0.4193\n",
            "Epoch 25/25\n",
            "180/180 [==============================] - 78s 414ms/step - c_loss: 1.5106 - c_acc: 0.9171 - r_acc: 0.5029 - p_loss: 1.5161 - p_acc: 0.4342 - val_p_loss: 1.5973 - val_p_acc: 0.4209\n"
          ]
        }
      ],
      "source": [
        "model = NNCLR(temperature=temperature, queue_size=queue_size)\n",
        "model.compile(\n",
        "    contrastive_optimizer=keras.optimizers.Adam(),\n",
        "    probe_optimizer=keras.optimizers.Adam(),\n",
        ")\n",
        "pretrain_history = model.fit(\n",
        "    train_dataset, epochs=num_epochs, validation_data=test_dataset\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh5ENjg72xvi",
        "outputId": "8da1e3a8-cfe0-4a92-c906-75f743f3083b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "185/185 [==============================] - 12s 41ms/step - loss: 1.9540 - acc: 0.2633 - val_loss: 1.6770 - val_acc: 0.3759\n",
            "Epoch 2/25\n",
            "185/185 [==============================] - 8s 33ms/step - loss: 1.5937 - acc: 0.3906 - val_loss: 1.5532 - val_acc: 0.4215\n",
            "Epoch 3/25\n",
            "185/185 [==============================] - 7s 28ms/step - loss: 1.4629 - acc: 0.4460 - val_loss: 1.4246 - val_acc: 0.4700\n",
            "Epoch 4/25\n",
            "185/185 [==============================] - 7s 29ms/step - loss: 1.3623 - acc: 0.4927 - val_loss: 1.4094 - val_acc: 0.4823\n",
            "Epoch 5/25\n",
            "185/185 [==============================] - 7s 29ms/step - loss: 1.2936 - acc: 0.5219 - val_loss: 1.3649 - val_acc: 0.4866\n",
            "Epoch 6/25\n",
            "185/185 [==============================] - 8s 32ms/step - loss: 1.2382 - acc: 0.5399 - val_loss: 1.3145 - val_acc: 0.5200\n",
            "Epoch 7/25\n",
            "185/185 [==============================] - 7s 28ms/step - loss: 1.1733 - acc: 0.5768 - val_loss: 1.2639 - val_acc: 0.5390\n",
            "Epoch 8/25\n",
            "185/185 [==============================] - 8s 28ms/step - loss: 1.1455 - acc: 0.5728 - val_loss: 1.2591 - val_acc: 0.5378\n",
            "Epoch 9/25\n",
            "185/185 [==============================] - 8s 33ms/step - loss: 1.0774 - acc: 0.6044 - val_loss: 1.2143 - val_acc: 0.5544\n",
            "Epoch 10/25\n",
            "185/185 [==============================] - 8s 34ms/step - loss: 1.0380 - acc: 0.6216 - val_loss: 1.2205 - val_acc: 0.5690\n",
            "Epoch 11/25\n",
            "185/185 [==============================] - 7s 27ms/step - loss: 1.0201 - acc: 0.6348 - val_loss: 1.1957 - val_acc: 0.5819\n",
            "Epoch 12/25\n",
            "185/185 [==============================] - 7s 28ms/step - loss: 0.9743 - acc: 0.6426 - val_loss: 1.1368 - val_acc: 0.6012\n",
            "Epoch 13/25\n",
            "185/185 [==============================] - 8s 33ms/step - loss: 0.9276 - acc: 0.6639 - val_loss: 1.1485 - val_acc: 0.5930\n",
            "Epoch 14/25\n",
            "185/185 [==============================] - 7s 28ms/step - loss: 0.8995 - acc: 0.6795 - val_loss: 1.1611 - val_acc: 0.5960\n",
            "Epoch 15/25\n",
            "185/185 [==============================] - 8s 28ms/step - loss: 0.8786 - acc: 0.6871 - val_loss: 1.1310 - val_acc: 0.6040\n",
            "Epoch 16/25\n",
            "185/185 [==============================] - 7s 30ms/step - loss: 0.9037 - acc: 0.6801 - val_loss: 1.1793 - val_acc: 0.5906\n",
            "Epoch 17/25\n",
            "185/185 [==============================] - 9s 39ms/step - loss: 0.8290 - acc: 0.7081 - val_loss: 1.1639 - val_acc: 0.5951\n",
            "Epoch 18/25\n",
            "185/185 [==============================] - 7s 28ms/step - loss: 0.8205 - acc: 0.7089 - val_loss: 1.1426 - val_acc: 0.6154\n",
            "Epoch 19/25\n",
            "185/185 [==============================] - 8s 28ms/step - loss: 0.7775 - acc: 0.7171 - val_loss: 1.1781 - val_acc: 0.6094\n",
            "Epoch 20/25\n",
            "185/185 [==============================] - 8s 33ms/step - loss: 0.7803 - acc: 0.7161 - val_loss: 1.1447 - val_acc: 0.6070\n",
            "Epoch 21/25\n",
            "185/185 [==============================] - 7s 28ms/step - loss: 0.7341 - acc: 0.7367 - val_loss: 1.1454 - val_acc: 0.6134\n",
            "Epoch 22/25\n",
            "185/185 [==============================] - 7s 29ms/step - loss: 0.7292 - acc: 0.7395 - val_loss: 1.1377 - val_acc: 0.6130\n",
            "Epoch 23/25\n",
            "185/185 [==============================] - 7s 30ms/step - loss: 0.7060 - acc: 0.7491 - val_loss: 1.1863 - val_acc: 0.6093\n",
            "Epoch 24/25\n",
            "185/185 [==============================] - 8s 28ms/step - loss: 0.6838 - acc: 0.7570 - val_loss: 1.2511 - val_acc: 0.5981\n",
            "Epoch 25/25\n",
            "185/185 [==============================] - 8s 28ms/step - loss: 0.6608 - acc: 0.7650 - val_loss: 1.1561 - val_acc: 0.6175\n"
          ]
        }
      ],
      "source": [
        "finetuning_model = keras.Sequential(\n",
        "    [\n",
        "        layers.Input(shape=input_shape),\n",
        "        augmenter(**classification_augmenter),\n",
        "        model.encoder,\n",
        "        layers.Dense(10),\n",
        "    ],\n",
        "    name=\"finetuning_model\",\n",
        ")\n",
        "finetuning_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
        ")\n",
        "\n",
        "finetuning_history = finetuning_model.fit(\n",
        "    labeled_train_dataset, epochs=num_epochs, validation_data=test_dataset\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
